2025-07-30 10:16:52,349 - mmseg - INFO - Multi-processing start method is `None`
2025-07-30 10:16:52,349 - mmseg - INFO - OpenCV num_threads is `1
2025-07-30 10:16:52,386 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr/local/cuda-11.3
NVCC: Cuda compilation tools, release 11.3, V11.3.58
GCC: gcc (GCC) 10.2.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.1.2
MMCV: 1.6.0
MMCV Compiler: GCC 10.2
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.26.0+
------------------------------------------------------------

2025-07-30 10:16:52,386 - mmseg - INFO - Distributed training: False
2025-07-30 10:16:55,612 - mmseg - INFO - Config:
feat_y_steps = [5, 10, 15, 20, 30, 40, 50, 60, 80, 100]
anchor_y_steps = [
    5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95,
    100
]
anchor_len = 20
dataset_type = 'OpenlaneDataset'
data_root = '/home2/wr21125091/Anchor3DLane/data/OpenLane'
img_norm_cfg = dict(
    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], to_rgb=True)
input_size = (320, 480)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', img_scale=(480, 320), keep_ratio=False),
    dict(
        type='Normalize',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225],
        to_rgb=True),
    dict(type='MaskGenerate', input_size=(320, 480)),
    dict(type='LaneFormat'),
    dict(
        type='Collect',
        keys=[
            'img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix', 'mask',
            'targets', 'image_id'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', img_scale=(480, 320), keep_ratio=False),
    dict(
        type='Normalize',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225],
        to_rgb=True),
    dict(type='MaskGenerate', input_size=(320, 480)),
    dict(type='LaneFormat'),
    dict(
        type='Collect',
        keys=[
            'img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix', 'mask',
            'targets', 'image_id'
        ])
]
dataset_config = dict(max_lanes=25, input_size=(320, 480))
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=4,
    train=dict(
        type='OpenlaneDataset',
        data_root='/home2/wr21125091/Anchor3DLane/data/OpenLane',
        data_list='training.txt',
        dataset_config=dict(max_lanes=25, input_size=(320, 480)),
        y_steps=[
            5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,
            90, 95, 100
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', img_scale=(480, 320), keep_ratio=False),
            dict(
                type='Normalize',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
                to_rgb=True),
            dict(type='MaskGenerate', input_size=(320, 480)),
            dict(type='LaneFormat'),
            dict(
                type='Collect',
                keys=[
                    'img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix',
                    'mask', 'targets', 'image_id'
                ])
        ]),
    test=dict(
        type='OpenlaneDataset',
        data_root='/home2/wr21125091/Anchor3DLane/data/OpenLane',
        y_steps=[
            5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,
            90, 95, 100
        ],
        data_list='validation.txt',
        dataset_config=dict(max_lanes=25, input_size=(320, 480)),
        test_mode=True,
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', img_scale=(480, 320), keep_ratio=False),
            dict(
                type='Normalize',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
                to_rgb=True),
            dict(type='MaskGenerate', input_size=(320, 480)),
            dict(type='LaneFormat'),
            dict(
                type='Collect',
                keys=[
                    'img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix',
                    'mask', 'targets', 'image_id'
                ])
        ]))
model = dict(
    type='Anchor3DLane',
    backbone=dict(
        type='ResNetV1c',
        depth=18,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 2, 4),
        strides=(1, 2, 1, 1),
        with_cp=False,
        style='pytorch'),
    pretrained='/home2/wr21125091/Anchor3DLane2/resnet18_v1c-b5776b93.pth',
    y_steps=[
        5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90,
        95, 100
    ],
    feat_y_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
    anchor_cfg=dict(
        pitches=[5, 2, 1, 0, -1, -2, -5],
        yaws=[
            30, 20, 15, 10, 7, 5, 3, 1, 0, -1, -3, -5, -7, -10, -15, -20, -30
        ],
        num_x=45,
        distances=[3]),
    db_cfg=dict(
        org_h=1280,
        org_w=1920,
        resize_h=320,
        resize_w=480,
        ipm_h=208,
        ipm_w=128,
        pitch=3,
        cam_height=1.55,
        crop_y=0,
        K=[[2015.0, 0.0, 960.0], [0.0, 2015.0, 540.0], [0.0, 0.0, 1.0]],
        top_view_region=[[-10, 103], [10, 103], [-10, 3], [10, 3]],
        max_2dpoints=10),
    attn_dim=64,
    feat_size=(80, 120),
    num_category=21,
    loss_lane=dict(
        type='LaneLoss',
        loss_weights=dict(
            cls_loss=1, reg_losses_x=1, reg_losses_z=1, reg_losses_vis=1),
        assign_cfg=dict(
            type='TopkAssigner',
            pos_k=3,
            neg_k=450,
            anchor_len=20,
            metric='Euclidean'),
        anchor_len=20,
        anchor_steps=[
            5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,
            90, 95, 100
        ]),
    train_cfg=dict(nms_thres=0, conf_threshold=0),
    test_cfg=dict(
        nms_thres=2,
        conf_threshold=0.2,
        test_conf=0.5,
        refine_vis=True,
        vis_thresh=0.5))
data_shuffle = True
optimizer = dict(type='AdamW', lr=0.0003, weight_decay=1e-05)
optimizer_config = dict()
lr_config = dict(policy='step', step=[76000, 85500], gamma=0.1, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=95000)
checkpoint_config = dict(by_epoch=False, interval=9500)
log_config = dict(
    interval=10,
    hooks=[
        dict(type='TextLoggerHook', by_epoch=False),
        dict(type='TensorboardLoggerHook')
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 100000000)]
cudnn_benchmark = True
work_dir = 'fx/openlane/anchor3dlane'
gpu_ids = [0]
auto_resume = False

2025-07-30 10:16:55,612 - mmseg - INFO - Set random seed to 946889775, deterministic: False
Name of parameter - Initialization information

backbone.base.base_layer.0.weight - torch.Size([16, 3, 7, 7]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.base_layer.1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.base_layer.1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level0.0.weight - torch.Size([16, 16, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level0.1.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level0.1.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level1.0.weight - torch.Size([32, 16, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level1.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level1.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree1.conv1.weight - torch.Size([64, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree1.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree2.conv1.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree2.conv2.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.tree2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.root.conv.weight - torch.Size([64, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.root.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.root.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.project.0.weight - torch.Size([64, 32, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.project.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level2.project.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree1.conv1.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree1.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree2.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree2.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.tree2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.root.conv.weight - torch.Size([128, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.root.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.root.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.project.0.weight - torch.Size([128, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.project.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree1.project.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree1.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree1.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree2.conv1.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree2.conv2.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.tree2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.root.conv.weight - torch.Size([128, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.root.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.tree2.root.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.project.0.weight - torch.Size([128, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.project.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level3.project.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree1.conv1.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree2.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree2.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.tree2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.root.conv.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.root.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.root.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.project.0.weight - torch.Size([256, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.project.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree1.project.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree1.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree1.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree2.conv1.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree2.conv2.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.tree2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.root.conv.weight - torch.Size([256, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.root.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.tree2.root.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.project.0.weight - torch.Size([256, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.project.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level4.project.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree1.conv1.weight - torch.Size([512, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree1.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree2.conv1.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree2.conv2.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.tree2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.root.conv.weight - torch.Size([512, 1280, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.root.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.root.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.project.0.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.project.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.level5.project.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.fc.weight - torch.Size([1000, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.base.fc.bias - torch.Size([1000]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.proj_1.actf.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.proj_1.actf.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.proj_1.conv.weight - torch.Size([256, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.proj_1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.proj_1.conv.conv_offset_mask.weight - torch.Size([27, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.proj_1.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.up_1.weight - torch.Size([256, 1, 4, 4]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.node_1.actf.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.node_1.actf.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.node_1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.node_1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.node_1.conv.conv_offset_mask.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_0.node_1.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_1.actf.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_1.actf.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_1.conv.weight - torch.Size([128, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_1.conv.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_1.conv.conv_offset_mask.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_1.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.up_1.weight - torch.Size([128, 1, 4, 4]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_1.actf.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_1.actf.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_1.conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_1.conv.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_1.conv.conv_offset_mask.weight - torch.Size([27, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_1.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_2.actf.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_2.actf.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_2.conv.weight - torch.Size([128, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_2.conv.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_2.conv.conv_offset_mask.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.proj_2.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.up_2.weight - torch.Size([128, 1, 4, 4]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_2.actf.0.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_2.actf.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_2.conv.weight - torch.Size([128, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_2.conv.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_2.conv.conv_offset_mask.weight - torch.Size([27, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_1.node_2.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_1.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_1.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_1.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_1.conv.conv_offset_mask.weight - torch.Size([27, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_1.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.up_1.weight - torch.Size([64, 1, 4, 4]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_1.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_1.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_1.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_1.conv.conv_offset_mask.weight - torch.Size([27, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_1.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_2.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_2.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_2.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_2.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_2.conv.conv_offset_mask.weight - torch.Size([27, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_2.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.up_2.weight - torch.Size([64, 1, 4, 4]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_2.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_2.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_2.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_2.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_2.conv.conv_offset_mask.weight - torch.Size([27, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_2.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_3.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_3.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_3.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_3.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_3.conv.conv_offset_mask.weight - torch.Size([27, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.proj_3.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.up_3.weight - torch.Size([64, 1, 4, 4]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_3.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_3.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_3.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_3.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_3.conv.conv_offset_mask.weight - torch.Size([27, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.dla_up.ida_2.node_3.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_1.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_1.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_1.conv.weight - torch.Size([64, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_1.conv.conv_offset_mask.weight - torch.Size([27, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_1.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.up_1.weight - torch.Size([64, 1, 4, 4]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_1.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_1.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_1.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_1.conv.conv_offset_mask.weight - torch.Size([27, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_1.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_2.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_2.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_2.conv.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_2.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_2.conv.conv_offset_mask.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.proj_2.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.up_2.weight - torch.Size([64, 1, 8, 8]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_2.actf.0.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_2.actf.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_2.conv.weight - torch.Size([64, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_2.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_2.conv.conv_offset_mask.weight - torch.Size([27, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

backbone.ida_up.node_2.conv.conv_offset_mask.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

anchor_projection.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

anchor_projection.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

cls_layer.0.layer.0.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

cls_layer.0.layer.0.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

cls_layer.0.layer.2.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

cls_layer.0.layer.2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

cls_layer.0.layer.4.weight - torch.Size([21, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

cls_layer.0.layer.4.bias - torch.Size([21]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_x_layer.0.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_x_layer.0.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_x_layer.0.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_x_layer.0.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_x_layer.0.layer.4.weight - torch.Size([20, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_x_layer.0.layer.4.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_z_layer.0.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_z_layer.0.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_z_layer.0.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_z_layer.0.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_z_layer.0.layer.4.weight - torch.Size([20, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_z_layer.0.layer.4.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_vis_layer.0.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_vis_layer.0.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_vis_layer.0.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_vis_layer.0.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_vis_layer.0.layer.4.weight - torch.Size([20, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reg_vis_layer.0.layer.4.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.class_head.0.weight - torch.Size([256, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.class_head.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.class_head.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.class_head.2.weight - torch.Size([3, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.class_head.2.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.0.0.weight - torch.Size([256, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.1.0.weight - torch.Size([256, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.2.0.weight - torch.Size([256, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.2.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.2.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.3.0.weight - torch.Size([256, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.3.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.3.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.4.0.weight - torch.Size([256, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.4.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.4.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.5.0.weight - torch.Size([256, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.5.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.5.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.6.0.weight - torch.Size([256, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.6.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.6.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.7.0.weight - torch.Size([256, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.7.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_features.7.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.0.0.weight - torch.Size([4, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.0.0.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.1.0.weight - torch.Size([2, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.1.0.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.2.0.weight - torch.Size([20, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.2.0.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.3.0.weight - torch.Size([3, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.3.0.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.4.0.weight - torch.Size([3, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.4.0.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.5.0.weight - torch.Size([8, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.5.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.5.1.weight - torch.Size([8, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.5.1.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.6.0.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.6.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.7.0.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.reg_heads.7.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_heatmap_conv.0.weight - torch.Size([256, 256, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_heatmap_conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_heatmap_conv.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_heatmap_conv.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_heatmap_conv.3.weight - torch.Size([3, 256, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_heatmap_conv.3.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_offset_conv.0.weight - torch.Size([256, 256, 3]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_offset_conv.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_offset_conv.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_offset_conv.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_offset_conv.3.weight - torch.Size([2, 256, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

heads.predictor.trunc_offset_conv.3.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reduce_conv.weight - torch.Size([64, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  

reduce_conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
2025-07-30 10:17:00,082 - mmseg - INFO - Anchor3DLane(
  (backbone): DLASeg(
    (base): DLA(
      (base_layer): Sequential(
        (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (level0): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (level1): Sequential(
        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (level2): Tree(
        (tree1): BasicBlock(
          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tree2): BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (root): Root(
          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (project): Sequential(
          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (level3): Tree(
        (tree1): Tree(
          (tree1): BasicBlock(
            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (tree2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (root): Root(
            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (project): Sequential(
            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (tree2): Tree(
          (tree1): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (tree2): BasicBlock(
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (root): Root(
            (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (project): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (level4): Tree(
        (tree1): Tree(
          (tree1): BasicBlock(
            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (tree2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (root): Root(
            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (project): Sequential(
            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (tree2): Tree(
          (tree1): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (tree2): BasicBlock(
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (root): Root(
            (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (project): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (level5): Tree(
        (tree1): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tree2): BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (root): Root(
          (conv): Conv2d(1280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (project): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (fc): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))
    )
    (dla_up): DLAUp(
      (ida_0): IDAUp(
        (proj_1): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (up_1): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
        (node_1): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
      (ida_1): IDAUp(
        (proj_1): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (up_1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
        (node_1): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (proj_2): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (up_2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
        (node_2): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
      (ida_2): IDAUp(
        (proj_1): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
        (node_1): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (proj_2): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (up_2): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
        (node_2): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (proj_3): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (up_3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
        (node_3): DeformConv(
          (actf): Sequential(
            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU(inplace=True)
          )
          (conv): DCN(
            (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
    )
    (ida_up): IDAUp(
      (proj_1): DeformConv(
        (actf): Sequential(
          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
        )
        (conv): DCN(
          (conv_offset_mask): Conv2d(128, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
      (node_1): DeformConv(
        (actf): Sequential(
          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
        )
        (conv): DCN(
          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (proj_2): DeformConv(
        (actf): Sequential(
          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
        )
        (conv): DCN(
          (conv_offset_mask): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (up_2): ConvTranspose2d(64, 64, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2), groups=64, bias=False)
      (node_2): DeformConv(
        (actf): Sequential(
          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU(inplace=True)
        )
        (conv): DCN(
          (conv_offset_mask): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
  )
  (anchor_projection): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
  (cls_layer): ModuleList(
    (0): DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=640, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=640, out_features=640, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=640, out_features=21, bias=True)
      )
    )
  )
  (reg_x_layer): ModuleList(
    (0): DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=64, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=64, out_features=20, bias=True)
      )
    )
  )
  (reg_z_layer): ModuleList(
    (0): DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=64, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=64, out_features=20, bias=True)
      )
    )
  )
  (reg_vis_layer): ModuleList(
    (0): DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=64, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=64, out_features=20, bias=True)
      )
    )
  )
  (lane_loss): LaneLoss()
  (aux_loss): ModuleList()
  (heads): Detect_Head(
    (predictor): _predictor(
      (class_head): Sequential(
        (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InPlaceABN(256, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])
        (2): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      )
      (reg_features): ModuleList(
        (0): Sequential(
          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): InPlaceABN(256, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])
        )
        (1): Sequential(
          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): InPlaceABN(256, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])
        )
        (2): Sequential(
          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): InPlaceABN(256, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])
        )
        (3): Sequential(
          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): InPlaceABN(256, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])
        )
        (4): Sequential(
          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): InPlaceABN(256, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])
        )
        (5): Sequential(
          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): InPlaceABN(256, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])
        )
        (6): Sequential(
          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): InPlaceABN(256, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])
        )
        (7): Sequential(
          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): InPlaceABN(256, eps=1e-05, momentum=0.1, affine=True, activation=leaky_relu[0.01])
        )
      )
      (reg_heads): ModuleList(
        (0): ModuleList(
          (0): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): ModuleList(
          (0): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): ModuleList(
          (0): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): ModuleList(
          (0): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
        )
        (4): ModuleList(
          (0): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
        )
        (5): ModuleList(
          (0): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))
          (1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))
        )
        (6): ModuleList(
          (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
        )
        (7): ModuleList(
          (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (trunc_heatmap_conv): Sequential(
        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=replicate)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Identity()
        (3): Conv1d(256, 3, kernel_size=(1,), stride=(1,))
      )
      (trunc_offset_conv): Sequential(
        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=replicate)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Identity()
        (3): Conv1d(256, 2, kernel_size=(1,), stride=(1,))
      )
    )
    (post_processor): PostProcessor()
  )
  (reduce_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
)
2025-07-30 10:17:00,135 - mmseg - INFO - Data shuffle: True
2025-07-30 10:17:00,202 - mmseg - INFO - Start running, host: wr21125091@ubun, work_dir: /home2/wr21125091/Anchor3DLane2/tools/fx/openlane/anchor3dlane
2025-07-30 10:17:00,203 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-07-30 10:17:00,203 - mmseg - INFO - workflow: [('train', 100000000)], max: 95000 iters
2025-07-30 10:17:00,203 - mmseg - INFO - Checkpoints will be saved to /home2/wr21125091/Anchor3DLane2/tools/fx/openlane/anchor3dlane by HardDiskBackend.
